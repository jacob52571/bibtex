@misc{zhou2024visionlanguagemodelsautonomous,
      title={Vision Language Models in Autonomous Driving: A Survey and Outlook}, 
      author={Xingcheng Zhou and Mingyu Liu and Ekim Yurtsever and Bare Luka Zagar and Walter Zimmer and Hu Cao and Alois C. Knoll},
      year={2024},
      eprint={2310.14414},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2310.14414}, 
}
@misc{bojarski2016endendlearningselfdriving,
      title={End to End Learning for Self-Driving Cars}, 
      author={Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D. Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao and Karol Zieba},
      year={2016},
      eprint={1604.07316},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1604.07316}, 
}
@misc{sadat2020perceivepredictplansafe,
      title={Perceive, Predict, and Plan: Safe Motion Planning Through Interpretable Semantic Representations}, 
      author={Abbas Sadat and Sergio Casas and Mengye Ren and Xinyu Wu and Pranaab Dhawan and Raquel Urtasun},
      year={2020},
      eprint={2008.05930},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2008.05930}, 
}
@misc{hu2023planningorientedautonomousdriving,
      title={Planning-oriented Autonomous Driving}, 
      author={Yihan Hu and Jiazhi Yang and Li Chen and Keyu Li and Chonghao Sima and Xizhou Zhu and Siqi Chai and Senyao Du and Tianwei Lin and Wenhai Wang and Lewei Lu and Xiaosong Jia and Qiang Liu and Jifeng Dai and Yu Qiao and Hongyang Li},
      year={2023},
      eprint={2212.10156},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.10156}, 
}
@misc{jiang2023vadvectorizedscenerepresentation,
      title={VAD: Vectorized Scene Representation for Efficient Autonomous Driving}, 
      author={Bo Jiang and Shaoyu Chen and Qing Xu and Bencheng Liao and Jiajie Chen and Helong Zhou and Qian Zhang and Wenyu Liu and Chang Huang and Xinggang Wang},
      year={2023},
      eprint={2303.12077},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2303.12077}, 
}
@misc{xu2024drivegpt4interpretableendtoendautonomous,
      title={DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model}, 
      author={Zhenhua Xu and Yujia Zhang and Enze Xie and Zhen Zhao and Yong Guo and Kwan-Yee. K. Wong and Zhenguo Li and Hengshuang Zhao},
      year={2024},
      eprint={2310.01412},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2310.01412}, 
}
@misc{jin2023adaptactionawaredrivingcaption,
      title={ADAPT: Action-aware Driving Caption Transformer}, 
      author={Bu Jin and Xinyu Liu and Yupeng Zheng and Pengfei Li and Hao Zhao and Tong Zhang and Yuhang Zheng and Guyue Zhou and Jingjing Liu},
      year={2023},
      eprint={2302.00673},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2302.00673}, 
}
@misc{wang2023drivemlmaligningmultimodallarge,
      title={DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving}, 
      author={Wenhai Wang and Jiangwei Xie and ChuanYang Hu and Haoming Zou and Jianan Fan and Wenwen Tong and Yang Wen and Silei Wu and Hanming Deng and Zhiqi Li and Hao Tian and Lewei Lu and Xizhou Zhu and Xiaogang Wang and Yu Qiao and Jifeng Dai},
      year={2023},
      eprint={2312.09245},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.09245}, 
}
@misc{pan2024vlpvisionlanguageplanning,
      title={VLP: Vision Language Planning for Autonomous Driving}, 
      author={Chenbin Pan and Burhaneddin Yaman and Tommaso Nesti and Abhirup Mallik and Alessandro G Allievi and Senem Velipasalar and Liu Ren},
      year={2024},
      eprint={2401.05577},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2401.05577}, 
}
@misc{fourati2024xlmautonomousdrivingsystems,
      title={XLM for Autonomous Driving Systems: A Comprehensive Review}, 
      author={Sonda Fourati and Wael Jaafar and Noura Baccar and Safwan Alfattani},
      year={2024},
      eprint={2409.10484},
      archivePrefix={arXiv},
      primaryClass={eess.SY},
      url={https://arxiv.org/abs/2409.10484}, 
}
@misc{wang2024omnidriveholisticllmagentframework,
      title={OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning}, 
      author={Shihao Wang and Zhiding Yu and Xiaohui Jiang and Shiyi Lan and Min Shi and Nadine Chang and Jan Kautz and Ying Li and Jose M. Alvarez},
      year={2024},
      eprint={2405.01533},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.01533}, 
}
@misc{zhang2024mmllmsrecentadvancesmultimodal,
      title={MM-LLMs: Recent Advances in MultiModal Large Language Models}, 
      author={Duzhen Zhang and Yahan Yu and Chenxing Li and Jiahua Dong and Dan Su and Chenhui Chu and Dong Yu},
      year={2024},
      eprint={2401.13601},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.13601}, 
}
@misc{tian2024drivevlmconvergenceautonomousdriving,
      title={DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models}, 
      author={Xiaoyu Tian and Junru Gu and Bailin Li and Yicheng Liu and Yang Wang and Zhiyong Zhao and Kun Zhan and Peng Jia and Xianpeng Lang and Hang Zhao},
      year={2024},
      eprint={2402.12289},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2402.12289}, 
}
@misc{liu2024surveyattackslargevisionlanguage,
      title={A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends}, 
      author={Daizong Liu and Mingyu Yang and Xiaoye Qu and Pan Zhou and Wei Hu and Yu Cheng},
      year={2024},
      eprint={2407.07403},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.07403}, 
}
@misc{zhang2024avibenchevaluatingrobustnesslarge,
      title={AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions}, 
      author={Hao Zhang and Wenqi Shao and Hong Liu and Yongqiang Ma and Ping Luo and Yu Qiao and Kaipeng Zhang},
      year={2024},
      eprint={2403.09346},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.09346}, 
}
@misc{madry2019deeplearningmodelsresistant,
      title={Towards Deep Learning Models Resistant to Adversarial Attacks}, 
      author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
      year={2019},
      eprint={1706.06083},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1706.06083}, 
}
@misc{carlini2017evaluatingrobustnessneuralnetworks,
      title={Towards Evaluating the Robustness of Neural Networks}, 
      author={Nicholas Carlini and David Wagner},
      year={2017},
      eprint={1608.04644},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1608.04644}, 
}
@misc{tramèr2020ensembleadversarialtrainingattacks,
      title={Ensemble Adversarial Training: Attacks and Defenses}, 
      author={Florian Tramèr and Alexey Kurakin and Nicolas Papernot and Ian Goodfellow and Dan Boneh and Patrick McDaniel},
      year={2020},
      eprint={1705.07204},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1705.07204}, 
}
@misc{cui2023robustnesslargemultimodalmodels,
      title={On the Robustness of Large Multimodal Models Against Image Adversarial Attacks}, 
      author={Xuanming Cui and Alejandro Aparcedo and Young Kyun Jang and Ser-Nam Lim},
      year={2023},
      eprint={2312.03777},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.03777}, 
}
@misc{fu2023misusingtoolslargelanguage,
      title={Misusing Tools in Large Language Models With Visual Adversarial Examples}, 
      author={Xiaohan Fu and Zihan Wang and Shuheng Li and Rajesh K. Gupta and Niloofar Mireshghallah and Taylor Berg-Kirkpatrick and Earlence Fernandes},
      year={2023},
      eprint={2310.03185},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2310.03185}, 
}
@misc{gao2024inducinghighenergylatencylarge,
      title={Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images}, 
      author={Kuofeng Gao and Yang Bai and Jindong Gu and Shu-Tao Xia and Philip Torr and Zhifeng Li and Wei Liu},
      year={2024},
      eprint={2401.11170},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2401.11170}, 
}
@misc{wu2025dissectingadversarialrobustnessmultimodal,
      title={Dissecting Adversarial Robustness of Multimodal LM Agents}, 
      author={Chen Henry Wu and Rishi Shah and Jing Yu Koh and Ruslan Salakhutdinov and Daniel Fried and Aditi Raghunathan},
      year={2025},
      eprint={2406.12814},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.12814}, 
}
@misc{dong2023robustgooglesbardadversarial,
      title={How Robust is Google's Bard to Adversarial Image Attacks?}, 
      author={Yinpeng Dong and Huanran Chen and Jiawei Chen and Zhengwei Fang and Xiao Yang and Yichi Zhang and Yu Tian and Hang Su and Jun Zhu},
      year={2023},
      eprint={2309.11751},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.11751}, 
}
@misc{touvron2021trainingdataefficientimagetransformers,
      title={Training data-efficient image transformers & distillation through attention}, 
      author={Hugo Touvron and Matthieu Cord and Matthijs Douze and Francisco Massa and Alexandre Sablayrolles and Hervé Jégou},
      year={2021},
      eprint={2012.12877},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2012.12877}, 
}
@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}
@misc{li2023blip2bootstrappinglanguageimagepretraining,
      title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      eprint={2301.12597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2301.12597}, 
}
@misc{tu2023unicornsimagesafetyevaluation,
      title={How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs}, 
      author={Haoqin Tu and Chenhang Cui and Zijun Wang and Yiyang Zhou and Bingchen Zhao and Junlin Han and Wangchunshu Zhou and Huaxiu Yao and Cihang Xie},
      year={2023},
      eprint={2311.16101},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.16101}, 
}
@misc{wang2024instructtainstructiontunedtargetedattack,
      title={InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language Models}, 
      author={Xunguang Wang and Zhenlan Ji and Pingchuan Ma and Zongjie Li and Shuai Wang},
      year={2024},
      eprint={2312.01886},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2312.01886}, 
}

@misc{cryptoeprint:2017/613,
      author = {Hocheol Shin and Dohyun Kim and Yujin Kwon and Yongdae Kim},
      title = {Illusion and Dazzle: Adversarial Optical Channel Exploits against Lidars for Automotive Applications},
      howpublished = {Cryptology {ePrint} Archive, Paper 2017/613},
      year = {2017},
      url = {https://eprint.iacr.org/2017/613}
}

